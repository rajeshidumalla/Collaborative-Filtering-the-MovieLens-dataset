{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Collaborative Filtering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557"
      },
      "source": [
        "# Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId"
      },
      "source": [
        "Let's setup Spark on Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qHai2252mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e677e5cf-04bd-4181-f5e7-a7f606312a19"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 66 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 61.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=9fcf289ae0341c75b4729c6d47f04d14f9bcec32068d7a436757f5e90de28066\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUUjUvXe3Sjk"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the filea we will be processing in the Spark job."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRElWs_x2mGh"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHsFTGUy2n1c"
      },
      "source": [
        "id='1QtPy_HuIMSzhtYllT3-WeM3Sqg55wK_D'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.training')\n",
        "\n",
        "id='1ePqnsQTJRRvQcBoF2EhoPU8CU1i5byHK'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.test')\n",
        "\n",
        "id='1ncUBWdI5AIt3FDUJokbMqpHD2knd5ebp'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('MovieLens.item')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ"
      },
      "source": [
        "If you executed the cells above, you should be able to see the dataset I will use for this Colab under the \"Files\" tab on the left panel.\n",
        "\n",
        "Next, I will import some of the common libraries needed for the task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twk-K-jilWK7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtrJlMBt1Ela"
      },
      "source": [
        "Let's initialize the Spark context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm3sAVeK1EDZ"
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqovskkH1DmC"
      },
      "source": [
        "We can easily check the current version and get the link of the web interface. In the Spark UI, we can monitor the progress of the job and debug the performance bottlenecks (if Colab is running with a **local runtime**)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DueQggJc1DDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "e3ebeb07-0daf-41e8-ae15-ff7d97c8edba"
      },
      "source": [
        "spark"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://805b744e894f:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9b7f992710>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iid7lXcG1CY8"
      },
      "source": [
        "If we are running this Colab on the Google hosted runtime, the cell below will create a *ngrok* tunnel which will allow us to still check the Spark UI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDnGLVPH1BPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff2af90-2e46-476a-eaa8-ac5cd3d65671"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-06 01:43:23--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.161.241.46, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  5.86MB/s    in 2.3s    \n",
            "\n",
            "2021-10-06 01:43:26 (5.86 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAYRX2PMm0L6"
      },
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hXdMR6wnEIM"
      },
      "source": [
        "In this Colab, I will be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/), specifically the 100K dataset (which contains in total 100,000 ratings from 1000 users on ~1700 movies).\n",
        "\n",
        "We load the ratings data in a 80%-20% ```training```/```test``` split, while the ```items``` dataframe contains the movie titles associated to the item identifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K93ABEy9Zlo"
      },
      "source": [
        "schema_ratings = StructType([\n",
        "    StructField(\"user_id\", IntegerType(), False),\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"rating\", IntegerType(), False),\n",
        "    StructField(\"timestamp\", IntegerType(), False)])\n",
        "\n",
        "schema_items = StructType([\n",
        "    StructField(\"item_id\", IntegerType(), False),\n",
        "    StructField(\"movie\", StringType(), False)])\n",
        "\n",
        "training = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.training\", header=False, schema=schema_ratings)\n",
        "test = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.test\", header=False, schema=schema_ratings)\n",
        "items = spark.read.option(\"sep\", \"|\").csv(\"MovieLens.item\", header=False, schema=schema_items)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC_m1oygCoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45770be7-36ae-4ea2-9dad-bffa122893f6"
      },
      "source": [
        "training.printSchema()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81Vgo4ovCqtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e978e38d-301c-421d-ca3a-f9a16e786469"
      },
      "source": [
        "items.printSchema()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- item_id: integer (nullable = true)\n",
            " |-- movie: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7"
      },
      "source": [
        "### Building ALS model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9w2aUvJ7KN"
      },
      "source": [
        "Let's compute some stats!  What is the number of ratings in the training and test dataset? How many movies are in our dataset?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XZaH16t_CIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4d390d-b118-42dd-c475-aa033f1b9f66"
      },
      "source": [
        "print( \"Number of ratings: \", training.count() )\n",
        "print( \"Number of movies: \", items.count() )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ratings:  80000\n",
            "Number of movies:  1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsaYOqRxar2"
      },
      "source": [
        "Using the training set, I will train a model with the Alternating Least Squares method available in the Spark MLlib: [https://spark.apache.org/docs/latest/ml-collaborative-filtering.html](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oitav_xhQD9w"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id\", itemCol=\"item_id\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\")\n",
        "model = als.fit(training)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtR1xRvonxiO"
      },
      "source": [
        "Now lets compute the RMSE on the test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP23Xkgwi0SD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9837a3-f9c5-4027-8c1d-a869ed4fde67"
      },
      "source": [
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 1.1264867353533161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBvSaWGEMHXI"
      },
      "source": [
        "At this point, we can use the trained model to produce the top-K recommendations for each user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbMlWL5_UfSc"
      },
      "source": [
        "# Generate top 10 movie recommendations for each user\n",
        "userRecs = model.recommendForAllUsers(10)\n",
        "# Generate top 10 user recommendations for each movie\n",
        "movieRecs = model.recommendForAllItems(10)\n",
        "\n",
        "ratings = training.union(test)\n",
        "\n",
        "# Generate top 10 movie recommendations for a specified set of users\n",
        "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
        "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
        "# Generate top 10 user recommendations for a specified set of movies\n",
        "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
        "movieSubSetRecs = model.recommendForItemSubset(movies, 10)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXc6nxWKHdAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bfbe965-2d7d-4443-b1aa-dd0e6221ee2e"
      },
      "source": [
        "userRecs.printSchema()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = false)\n",
            " |-- recommendations: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- item_id: integer (nullable = true)\n",
            " |    |    |-- rating: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a85Bxyw2J9pI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37945aa8-5893-4a1d-eacd-5a882d5f507f"
      },
      "source": [
        "movieRecs.printSchema()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- item_id: integer (nullable = false)\n",
            " |-- recommendations: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- user_id: integer (nullable = true)\n",
            " |    |    |-- rating: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JmQo7PbJkF_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51f9653-7bd8-471f-ffef-91ed1e82c807"
      },
      "source": [
        "userRecs.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|user_id|     recommendations|\n",
            "+-------+--------------------+\n",
            "|    471|[{1036, 12.422939...|\n",
            "|    463|[{793, 5.794737},...|\n",
            "|    833|[{1368, 6.2343984...|\n",
            "|    496|[{1240, 7.7203727...|\n",
            "|    148|[{1205, 10.957403...|\n",
            "|    540|[{1643, 6.031493}...|\n",
            "|    392|[{1615, 6.611747}...|\n",
            "|    243|[{1615, 6.749518}...|\n",
            "|    623|[{1473, 8.838204}...|\n",
            "|    737|[{1120, 9.00234},...|\n",
            "|    897|[{1643, 6.112293}...|\n",
            "|    858|[{793, 8.010915},...|\n",
            "|     31|[{853, 10.205002}...|\n",
            "|    516|[{624, 8.397214},...|\n",
            "|    580|[{1069, 9.959866}...|\n",
            "|    251|[{1278, 6.5018854...|\n",
            "|    451|[{1001, 7.89084},...|\n",
            "|     85|[{1473, 5.3242583...|\n",
            "|    137|[{962, 9.554027},...|\n",
            "|    808|[{1021, 8.569424}...|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUzueKJmL3IS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "232343a1-e8ce-4ced-aef3-5aba551f1951"
      },
      "source": [
        "flat_userRecs = userRecs.withColumn(\"recommendations\", explode(col(\"recommendations\"))).select('user_id', 'recommendations.*')\n",
        "flat_userRecs.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+\n",
            "|user_id|item_id|   rating|\n",
            "+-------+-------+---------+\n",
            "|    471|   1036|12.422939|\n",
            "|    471|   1664|  9.98227|\n",
            "|    471|    958| 9.943821|\n",
            "|    471|    440| 9.678638|\n",
            "|    471|    793| 9.591538|\n",
            "|    471|    889| 9.442203|\n",
            "|    471|    394| 8.993095|\n",
            "|    471|   1066| 8.941356|\n",
            "|    471|   1062| 8.351093|\n",
            "|    471|   1185| 8.307676|\n",
            "|    463|    793| 5.794737|\n",
            "|    463|   1466|5.6591215|\n",
            "|    463|   1113| 5.562354|\n",
            "|    463|   1282|  5.51689|\n",
            "|    463|    262| 5.374179|\n",
            "|    463|   1192| 5.339427|\n",
            "|    463|    889|5.2256794|\n",
            "|    463|    909| 5.094523|\n",
            "|    463|    980|4.9581914|\n",
            "|    463|    613|4.8710012|\n",
            "+-------+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atHmCmcbHp5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a893ce-d6b9-492d-9bea-2a5f55e66648"
      },
      "source": [
        "# lets read the recommendations more meaningful\n",
        "flat_userRecs.join(items, flat_userRecs.item_id == items.item_id).show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+-------+--------------------+\n",
            "|user_id|item_id|   rating|item_id|               movie|\n",
            "+-------+-------+---------+-------+--------------------+\n",
            "|    471|   1036|12.422939|   1036|Drop Dead Fred (1...|\n",
            "|    471|   1664|  9.98227|   1664|8 Heads in a Duff...|\n",
            "|    471|    958| 9.943821|    958|To Live (Huozhe) ...|\n",
            "|    471|    440| 9.678638|    440|Amityville II: Th...|\n",
            "|    471|    793| 9.591538|    793|     Crooklyn (1994)|\n",
            "|    471|    889| 9.442203|    889|Tango Lesson, The...|\n",
            "|    471|    394| 8.993095|    394|Radioland Murders...|\n",
            "|    471|   1066| 8.941356|   1066|        Balto (1995)|\n",
            "|    471|   1062| 8.351093|   1062|Four Days in Sept...|\n",
            "|    471|   1185| 8.307676|   1185|In the Army Now (...|\n",
            "|    463|    793| 5.794737|    793|     Crooklyn (1994)|\n",
            "|    463|   1466|5.6591215|   1466|Margaret's Museum...|\n",
            "|    463|   1113| 5.562354|   1113|Mrs. Parker and t...|\n",
            "|    463|   1282|  5.51689|   1282|Grass Harp, The (...|\n",
            "|    463|    262| 5.374179|    262|In the Company of...|\n",
            "|    463|   1192| 5.339427|   1192|Boys of St. Vince...|\n",
            "|    463|    889|5.2256794|    889|Tango Lesson, The...|\n",
            "|    463|    909| 5.094523|    909|Dangerous Beauty ...|\n",
            "|    463|    980|4.9581914|    980| Mother Night (1996)|\n",
            "|    463|    613|4.8710012|    613|My Man Godfrey (1...|\n",
            "+-------+-------+---------+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYvaDcSbSfDF"
      },
      "source": [
        "We can tune the ALS model by changing the maxIter, regParam which will give us a better recommendations but it will take more execution time to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewPlrCmhQWQO"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}